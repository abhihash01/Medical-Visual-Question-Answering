{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKZHDm_a9a2f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def load_jsonl(path):\n",
        "    data=[]\n",
        "    with open(path, 'r', encoding='utf-8') as reader:\n",
        "        for line in reader:\n",
        "            data.append(json.loads(line))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "contractions = {\n",
        "    \"aint\": \"ain't\",\n",
        "    \"arent\": \"aren't\",\n",
        "    \"cant\": \"can't\",\n",
        "    \"couldve\": \"could've\",\n",
        "    \"couldnt\": \"couldn't\",\n",
        "    \"couldn'tve\": \"couldn't've\",\n",
        "    \"couldnt've\": \"couldn't've\",\n",
        "    \"didnt\": \"didn't\",\n",
        "    \"doesnt\": \"doesn't\",\n",
        "    \"dont\": \"don't\",\n",
        "    \"hadnt\": \"hadn't\",\n",
        "    \"hadnt've\": \"hadn't've\",\n",
        "    \"hadn'tve\": \"hadn't've\",\n",
        "    \"hasnt\": \"hasn't\",\n",
        "    \"havent\": \"haven't\",\n",
        "    \"hed\": \"he'd\",\n",
        "    \"hed've\": \"he'd've\",\n",
        "    \"he'dve\": \"he'd've\",\n",
        "    \"hes\": \"he's\",\n",
        "    \"howd\": \"how'd\",\n",
        "    \"howll\": \"how'll\",\n",
        "    \"hows\": \"how's\",\n",
        "    \"Id've\": \"I'd've\",\n",
        "    \"I'dve\": \"I'd've\",\n",
        "    \"Im\": \"I'm\",\n",
        "    \"Ive\": \"I've\",\n",
        "    \"isnt\": \"isn't\",\n",
        "    \"itd\": \"it'd\",\n",
        "    \"itd've\": \"it'd've\",\n",
        "    \"it'dve\": \"it'd've\",\n",
        "    \"itll\": \"it'll\",\n",
        "    \"let's\": \"let's\",\n",
        "    \"maam\": \"ma'am\",\n",
        "    \"mightnt\": \"mightn't\",\n",
        "    \"mightnt've\": \"mightn't've\",\n",
        "    \"mightn'tve\": \"mightn't've\",\n",
        "    \"mightve\": \"might've\",\n",
        "    \"mustnt\": \"mustn't\",\n",
        "    \"mustve\": \"must've\",\n",
        "    \"neednt\": \"needn't\",\n",
        "    \"notve\": \"not've\",\n",
        "    \"oclock\": \"o'clock\",\n",
        "    \"oughtnt\": \"oughtn't\",\n",
        "    \"ow's'at\": \"'ow's'at\",\n",
        "    \"'ows'at\": \"'ow's'at\",\n",
        "    \"'ow'sat\": \"'ow's'at\",\n",
        "    \"shant\": \"shan't\",\n",
        "    \"shed've\": \"she'd've\",\n",
        "    \"she'dve\": \"she'd've\",\n",
        "    \"she's\": \"she's\",\n",
        "    \"shouldve\": \"should've\",\n",
        "    \"shouldnt\": \"shouldn't\",\n",
        "    \"shouldnt've\": \"shouldn't've\",\n",
        "    \"shouldn'tve\": \"shouldn't've\",\n",
        "    \"somebody'd\": \"somebodyd\",\n",
        "    \"somebodyd've\": \"somebody'd've\",\n",
        "    \"somebody'dve\": \"somebody'd've\",\n",
        "    \"somebodyll\": \"somebody'll\",\n",
        "    \"somebodys\": \"somebody's\",\n",
        "    \"someoned\": \"someone'd\",\n",
        "    \"someoned've\": \"someone'd've\",\n",
        "    \"someone'dve\": \"someone'd've\",\n",
        "    \"someonell\": \"someone'll\",\n",
        "    \"someones\": \"someone's\",\n",
        "    \"somethingd\": \"something'd\",\n",
        "    \"somethingd've\": \"something'd've\",\n",
        "    \"something'dve\": \"something'd've\",\n",
        "    \"somethingll\": \"something'll\",\n",
        "    \"thats\": \"that's\",\n",
        "    \"thered\": \"there'd\",\n",
        "    \"thered've\": \"there'd've\",\n",
        "    \"there'dve\": \"there'd've\",\n",
        "    \"therere\": \"there're\",\n",
        "    \"theres\": \"there's\",\n",
        "    \"theyd\": \"they'd\",\n",
        "    \"theyd've\": \"they'd've\",\n",
        "    \"they'dve\": \"they'd've\",\n",
        "    \"theyll\": \"they'll\",\n",
        "    \"theyre\": \"they're\",\n",
        "    \"theyve\": \"they've\",\n",
        "    \"twas\": \"'twas\",\n",
        "    \"wasnt\": \"wasn't\",\n",
        "    \"wed've\": \"we'd've\",\n",
        "    \"we'dve\": \"we'd've\",\n",
        "    \"weve\": \"we've\",\n",
        "    \"werent\": \"weren't\",\n",
        "    \"whatll\": \"what'll\",\n",
        "    \"whatre\": \"what're\",\n",
        "    \"whats\": \"what's\",\n",
        "    \"whatve\": \"what've\",\n",
        "    \"whens\": \"when's\",\n",
        "    \"whered\": \"where'd\",\n",
        "    \"wheres\": \"where's\",\n",
        "    \"whereve\": \"where've\",\n",
        "    \"whod\": \"who'd\",\n",
        "    \"whod've\": \"who'd've\",\n",
        "    \"who'dve\": \"who'd've\",\n",
        "    \"wholl\": \"who'll\",\n",
        "    \"whos\": \"who's\",\n",
        "    \"whove\": \"who've\",\n",
        "    \"whyll\": \"why'll\",\n",
        "    \"whyre\": \"why're\",\n",
        "    \"whys\": \"why's\",\n",
        "    \"wont\": \"won't\",\n",
        "    \"wouldve\": \"would've\",\n",
        "    \"wouldnt\": \"wouldn't\",\n",
        "    \"wouldnt've\": \"wouldn't've\",\n",
        "    \"wouldn'tve\": \"wouldn't've\",\n",
        "    \"yall\": \"y'all\",\n",
        "    \"yall'll\": \"y'all'll\",\n",
        "    \"y'allll\": \"y'all'll\",\n",
        "    \"yall'd've\": \"y'all'd've\",\n",
        "    \"y'alld've\": \"y'all'd've\",\n",
        "    \"y'all'dve\": \"y'all'd've\",\n",
        "    \"youd\": \"you'd\",\n",
        "    \"youd've\": \"you'd've\",\n",
        "    \"you'dve\": \"you'd've\",\n",
        "    \"youll\": \"you'll\",\n",
        "    \"youre\": \"you're\",\n",
        "    \"youve\": \"you've\",\n",
        "}\n",
        "\n",
        "manual_map = {\n",
        "    \"none\": \"0\",\n",
        "    \"zero\": \"0\",\n",
        "    \"one\": \"1\",\n",
        "    \"two\": \"2\",\n",
        "    \"three\": \"3\",\n",
        "    \"four\": \"4\",\n",
        "    \"five\": \"5\",\n",
        "    \"six\": \"6\",\n",
        "    \"seven\": \"7\",\n",
        "    \"eight\": \"8\",\n",
        "    \"nine\": \"9\",\n",
        "    \"ten\": \"10\",\n",
        "}\n",
        "articles = [\"a\", \"an\", \"the\"]\n",
        "period_strip = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
        "comma_strip = re.compile(\"(\\d)(\\,)(\\d)\")\n",
        "punct = [\n",
        "    \";\",\n",
        "    r\"/\",\n",
        "    \"[\",\n",
        "    \"]\",\n",
        "    '\"',\n",
        "    \"{\",\n",
        "    \"}\",\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    \"=\",\n",
        "    \"+\",\n",
        "    \"\\\\\",\n",
        "    \"_\",\n",
        "    \"-\",\n",
        "    \">\",\n",
        "    \"<\",\n",
        "    \"@\",\n",
        "    \"`\",\n",
        "    \",\",\n",
        "    \"?\",\n",
        "    \"!\",\n",
        "]\n",
        "\n",
        "\n",
        "def normalize_word(token):\n",
        "    _token = token\n",
        "    for p in punct:\n",
        "        if (p + \" \" in token or \" \" + p in token) or (\n",
        "            re.search(comma_strip, token) != None\n",
        "        ):\n",
        "            _token = _token.replace(p, \"\")\n",
        "        else:\n",
        "            _token = _token.replace(p, \" \")\n",
        "    token = period_strip.sub(\"\", _token, re.UNICODE)\n",
        "\n",
        "    _token = []\n",
        "    temp = token.lower().split()\n",
        "    for word in temp:\n",
        "        word = manual_map.setdefault(word, word)\n",
        "        if word not in articles:\n",
        "            _token.append(word)\n",
        "    for i, word in enumerate(_token):\n",
        "        if word in contractions:\n",
        "            _token[i] = contractions[word]\n",
        "    token = \" \".join(_token)\n",
        "    token = token.replace(\",\", \"\")\n",
        "    return token"
      ],
      "metadata": {
        "id": "UZCT7Jo6EHYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def split_sentence(sentence, n):\n",
        "    words = defaultdict(int)\n",
        "    # tmp_sentence = re.sub(\"[^a-zA-Z ]\", \"\", sentence)\n",
        "    tmp_sentence = sentence\n",
        "    tmp_sentence = tmp_sentence.lower()\n",
        "    tmp_sentence = tmp_sentence.strip().split()\n",
        "    length = len(tmp_sentence)\n",
        "    for i in range(length - n + 1):\n",
        "        tmp_words = \" \".join(tmp_sentence[i: i + n])\n",
        "        if tmp_words:\n",
        "            words[tmp_words] += 1\n",
        "    return words"
      ],
      "metadata": {
        "id": "o87ErV-0Na7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_exactmatch(candidate, reference):\n",
        "\n",
        "    candidate = normalize_word(candidate)\n",
        "    reference = normalize_word(reference)\n",
        "\n",
        "    candidate_words = split_sentence(candidate, 1)\n",
        "    reference_words = split_sentence(reference, 1)\n",
        "    count = 0\n",
        "    total = 0\n",
        "    for word in reference_words:\n",
        "        if word in candidate_words:\n",
        "            count += 1\n",
        "    for word in candidate_words:\n",
        "        total += candidate_words[word]\n",
        "\n",
        "    if total == 0:\n",
        "        return 0 # \"0 (warning: length of candidate's words is 0)\"\n",
        "    else:\n",
        "        return count / total\n"
      ],
      "metadata": {
        "id": "Axam8_1cNLQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1score(candidate, reference):\n",
        "\n",
        "    candidate = normalize_word(candidate)\n",
        "    reference = normalize_word(reference)\n",
        "\n",
        "    candidate_words = split_sentence(candidate, 1)\n",
        "    reference_words = split_sentence(reference, 1)\n",
        "    word_set = set()\n",
        "    for word in candidate_words:\n",
        "        word_set.add(word)\n",
        "    for word in reference_words:\n",
        "        word_set.add(word)\n",
        "\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for word in word_set:\n",
        "        if word in candidate_words and word in reference_words:\n",
        "            tp += candidate_words[word]\n",
        "        elif word in candidate_words and word not in reference_words:\n",
        "            fp += candidate_words[word]\n",
        "        elif word not in candidate_words and word in reference_words:\n",
        "            fn += reference_words[word]\n",
        "\n",
        "    if len(candidate_words) == 0:\n",
        "        return 0, 0, 0 # \"0 (warning: length of candidate's words is 0)\"\n",
        "    elif len(reference_words) == 0:\n",
        "        return 0, 0, 0\n",
        "    else:\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        if tp == 0:\n",
        "            return 0, 0, 0\n",
        "        else:\n",
        "            return 2 * precision * recall / (precision + recall), precision, recall\n"
      ],
      "metadata": {
        "id": "oQl4Sx70N8uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from tabulate import tabulate\n",
        "def evaluate(gt, pred):\n",
        "  closed_scores = collections.defaultdict(list)\n",
        "  open_hit_scores = collections.defaultdict(list)\n",
        "  exact_scores = collections.defaultdict(list)\n",
        "  f1_scores = collections.defaultdict(list)\n",
        "  f1_scores_closed = collections.defaultdict(list)\n",
        "  for gt_item, pred_item in zip(gt,pred):\n",
        "    if gt_item['qid']== pred_item['question_id']:\n",
        "      if isinstance(gt_item['answer'], int):\n",
        "            gt_item['answer'] = str(gt_item['answer'])\n",
        "      if isinstance(pred_item['text'], int):\n",
        "            pred_item['text'] = str(pred_item['text'])\n",
        "      gt_value = gt_item['answer'].lower()\n",
        "      pred_value = pred_item['text'].lower()\n",
        "      gt_value = normalize_word(gt_value)\n",
        "      pred_value = normalize_word(pred_value)\n",
        "      if gt_item['answer_type'] == 'OPEN':\n",
        "        if gt_value in pred_value:\n",
        "          open_hit_scores['hit'].append(1)\n",
        "        else:\n",
        "          open_hit_scores['hit'].append(0)\n",
        "        open_hit_scores['qid'].append(pred_item['question_id'])\n",
        "        exact_scores['hit'].append(calculate_exactmatch(pred_value, gt_value))\n",
        "        exact_scores['q_id'].append(pred_item['question_id'])\n",
        "        f1_score, precision, recall = calculate_f1score(pred_value, gt_value)\n",
        "        f1_scores['f1'].append(f1_score)\n",
        "        f1_scores['precision'].append(precision)\n",
        "        f1_scores['recall'].append(recall)\n",
        "        f1_scores['q_id'].append(pred_item['question_id'])\n",
        "      elif gt_item['answer_type'] == 'CLOSED':\n",
        "        # for close-ended question (Yes/No)\n",
        "        closed_scores['q_id'].append(pred_item['question_id'])\n",
        "\n",
        "        f1_score_closed, precision_closed, recall_closed = calculate_f1score(pred_value, gt_value)\n",
        "        f1_scores_closed['f1'].append(f1_score_closed)\n",
        "        f1_scores_closed['precision'].append(precision_closed)\n",
        "        f1_scores_closed['recall'].append(recall_closed)\n",
        "        f1_scores_closed['q_id'].append(pred_item['question_id'])\n",
        "\n",
        "\n",
        "\n",
        "        if gt_value in pred_value:\n",
        "          closed_scores['hit'].append(1)\n",
        "        else:\n",
        "          closed_scores['hit'].append(0)\n",
        "\n",
        "  exact_score = sum(exact_scores['hit']) / len(exact_scores['hit'])\n",
        "  f1_score = sum(f1_scores['f1']) / len(f1_scores['f1'])\n",
        "  precision = sum(f1_scores['precision']) / len(f1_scores['precision'])\n",
        "  recall = sum(f1_scores['recall']) / len(f1_scores['recall'])\n",
        "\n",
        "\n",
        "  open_hit_score = sum(open_hit_scores['hit']) / len(open_hit_scores['hit']) if len(open_hit_scores['hit']) != 0 else 0.0\n",
        "  closed_score = sum(closed_scores['hit']) / len(closed_scores['hit']) if len(closed_scores['hit']) != 0 else 0.0\n",
        "  #print(closed_scores)\n",
        "\n",
        "  recall_closed = sum(f1_scores_closed['recall']) / len(f1_scores_closed['recall'])\n",
        "\n",
        "  num_open, num_close = len(open_hit_scores['hit']), len(closed_scores['hit'])\n",
        "  print(f'num_open {num_open} || num_close {num_close}')\n",
        "\n",
        "\n",
        "\n",
        "  num_open, num_close = len(open_hit_scores['hit']), len(closed_scores['hit'])\n",
        "  print(f'num_open {num_open} || num_close {num_close}')\n",
        "  return tabulate(\n",
        "        [\n",
        "            ['exact match score', exact_score*100],\n",
        "            ['f1 score', f1_score*100],\n",
        "            ['precision', precision*100],\n",
        "            ['recall', recall*100],\n",
        "            ['open accuracy', open_hit_score*100],\n",
        "            ['yes/no accuracy', closed_score*100],\n",
        "            ['recall_closed', recall_closed*100]\n",
        "        ],\n",
        "        headers=['Metric', 'Performance']\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ocJsHPVPJlyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHAnbgk3RaCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seperate_recall(reference,candidate):\n",
        "  candidate = normalize_word(candidate)\n",
        "  reference = normalize_word(reference)\n",
        "\n",
        "  candidate_words = split_sentence(candidate, 1)\n",
        "  reference_words = split_sentence(reference, 1)\n",
        "  word_set = set()\n",
        "  for word in candidate_words:\n",
        "    word_set.add(word)\n",
        "  for word in reference_words:\n",
        "    word_set.add(word)\n",
        "\n",
        "  present_words_count = 0\n",
        "  reference_words_count = 0\n",
        "  for word in word_set:\n",
        "    if word in reference_words and word in candidate_words:\n",
        "      present_words_count = present_words_count+1\n",
        "    if word in reference_words:\n",
        "      reference_words_count = reference_words_count+1\n",
        "\n",
        "  if present_words_count>= reference_words_count:\n",
        "    return 1\n",
        "  else:\n",
        "    return present_words_count/reference_words_count"
      ],
      "metadata": {
        "id": "9Rrrq00zRt9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recall(gt, pred):\n",
        "  recall_scores = []\n",
        "  print(len(gt))\n",
        "  print(len(pred))\n",
        "  for gt_item, pred_item in zip(gt,pred):\n",
        "    if gt_item['qid']== pred_item['question_id']:\n",
        "      gt_value = gt_item['answer'].lower()\n",
        "      pred_value = pred_item['text'].lower()\n",
        "      gt_value = normalize_word(gt_value)\n",
        "      pred_value = normalize_word(pred_value)\n",
        "      if gt_item['answer_type'] == 'OPEN':\n",
        "        recall_scores.append(seperate_recall(gt_value, pred_value))\n",
        "  print(recall_scores)\n",
        "  return sum(recall_scores)/len(recall_scores)"
      ],
      "metadata": {
        "id": "XW6I0334Raw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfIr3k9W7VCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOu6XNl07U9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests for fine tuned llava 1.0 models"
      ],
      "metadata": {
        "id": "50icccsq7WCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slake_pred = json.load(open('llava_1.5_slake_pred.json','r'))\n",
        "slake_test = json.load(open('english_slake_test.json','r'))\n",
        "vqa_pred = json.load(open('llava_1.5_slake_pred.json','r'))\n",
        "vqa_test = json.load(open('test_vqa_rad.json','r'))\n",
        "slake_pred_model_1 = load_jsonl('llava-1.0-slake.jsonl')\n",
        "vqa_pred_model_1= load_jsonl('llava-1.0-vqa_rad.jsonl')\n",
        "slake_pred_finetuned = load_jsonl('llava-1.0-finetuned-slake.jsonl')\n",
        "vqa_pred_finetuned = load_jsonl('llava-1.0-finetuned-vqa-rad.jsonl')"
      ],
      "metadata": {
        "id": "8LBT4BFl7U4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p5=evaluate(slake_test,slake_pred_model_1)\n",
        "p6 = evaluate(vqa_test,vqa_pred_model_1)\n",
        "p7 = evaluate(slake_test,slake_pred_finetuned)\n",
        "p8 = evaluate(vqa_test,vqa_pred_finetuned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DdMtmov7Uz0",
        "outputId": "1c87831b-4436-427d-9291-1907998d2a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_open 645 || num_close 416\n",
            "num_open 645 || num_close 416\n",
            "num_open 179 || num_close 272\n",
            "num_open 179 || num_close 272\n",
            "num_open 645 || num_close 416\n",
            "num_open 645 || num_close 416\n",
            "num_open 179 || num_close 272\n",
            "num_open 179 || num_close 272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmtb8zxl7VSq",
        "outputId": "3f60b33d-cfc6-4194-b471-83ad41c07c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        3.88346\n",
            "f1 score                 7.75965\n",
            "precision                4.51237\n",
            "recall                  39.7152\n",
            "open accuracy           31.7829\n",
            "yes/no accuracy         56.25\n",
            "recall_closed           46.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLiT70Fm7VNt",
        "outputId": "fab6e3a5-ebcb-436e-810d-9687c501d340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        4.60586\n",
            "f1 score                 8.05917\n",
            "precision                5.01149\n",
            "recall                  28.8164\n",
            "open accuracy           15.0838\n",
            "yes/no accuracy         61.3971\n",
            "recall_closed           46.5074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pMK5-Us7VI7",
        "outputId": "4fb7269d-fe04-4e00-9b83-9ce03c27e03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        47.676\n",
            "f1 score                 60.6785\n",
            "precision                48.17\n",
            "recall                   84.479\n",
            "open accuracy            79.6899\n",
            "yes/no accuracy          42.5481\n",
            "recall_closed            42.5481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2iSywQd7Uu9",
        "outputId": "9a5ad7e0-f13c-4fd0-ecef-af524c8c4b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        42.5822\n",
            "f1 score                 50.7351\n",
            "precision                42.7452\n",
            "recall                   64.7393\n",
            "open accuracy            59.7765\n",
            "yes/no accuracy          32.7206\n",
            "recall_closed            22.0588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D04E9w7M7UqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparision with llava 1.5"
      ],
      "metadata": {
        "id": "k2Zylbou9Vxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(p1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N33sJGK7UlG",
        "outputId": "0ce2fbcd-13d3-4fbd-ba0c-fac7f6200135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        6.02756\n",
            "f1 score                11.1898\n",
            "precision                6.72133\n",
            "recall                  43.9545\n",
            "open accuracy           37.8295\n",
            "yes/no accuracy         60.5769\n",
            "recall_closed           56.3702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvVPbF3T7UgW",
        "outputId": "c4709fbb-d5ce-4e87-ed83-91a93a8315c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric               Performance\n",
            "-----------------  -------------\n",
            "exact match score        6.55968\n",
            "f1 score                10.5678\n",
            "precision                6.90923\n",
            "recall                  31.9855\n",
            "open accuracy           18.9944\n",
            "yes/no accuracy         67.2794\n",
            "recall_closed           55.5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMk0f0K07Ube"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W5uwORUo7UWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-x4lNx37UR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rl1Nka3y7UNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xvKnPykW7UIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xMiRl2ok7UD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OVyNveEq7T_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7knv6km7T62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "abBSF8iA7T2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yGEQJrv7Txm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4DAGwvW7Ts2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvq70Tsl7ToS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Qq3u2Pf7TkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pM7Ipllr7Tf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHpqc57P7Tbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Nc9UDYV7TXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzEbLvL87TTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJFiYoaS7TPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ni2sifIJ7TKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_9nGdEeM7TDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjmtkPKq7S9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHemWOQT_wsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}